{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegNet implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution layer. takes parameters; input tensor, number of filters and kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input, filters, kernel_size = 7):\n",
    "    return tf.layers.conv2d(\n",
    "            inputs = input,\n",
    "            filters = filters,\n",
    "            kernel_size = [kernel_size, kernel_size],\n",
    "            padding = \"same\",\n",
    "            activation = tf.nn.relu\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution layer. takes parameters; input tensor, number of filters. Same as the Convolution layer except that it neglects the biases and does not apply activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv_layer(input,filters):\n",
    "    return tf.layers.conv2d(\n",
    "            inputs = input,\n",
    "            filters = filters,\n",
    "            kernel_size = [7,7],\n",
    "            padding = \"same\",\n",
    "            use_bias=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max pool layer which takes input tensor and returns a tensor with half size and map of the max pooled tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool_layer(input):\n",
    "    return(tf.nn.max_pool_with_argmax(input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unpool layer which takes an input tensor and the map of indices and returns the unpooled tensor of double size of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpool_layer(input, index, ksize=[1, 2, 2, 1]):\n",
    "    input_shape = input.get_shape().as_list()\n",
    "    output_shape = (input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3])\n",
    "\n",
    "    flat_output_shape = [output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]]\n",
    "\n",
    "    uppool = tf.reshape(input, [np.prod(input_shape)])\n",
    "    batch_range = tf.reshape(tf.range(output_shape[0], dtype=index.dtype), shape=[input_shape[0], 1, 1, 1])\n",
    "    b = tf.ones_like(index) * batch_range\n",
    "    b = tf.reshape(b, [np.prod(input_shape), 1])\n",
    "    ind = tf.reshape(index, [np.prod(input_shape), 1])\n",
    "    ind = tf.concat([b, ind], 1)\n",
    "\n",
    "    output = tf.scatter_nd(ind, uppool, shape=flat_output_shape)\n",
    "    return tf.reshape(output, output_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main model of Segnet which consists of 13 Convolution layer, 5 max pooling layers, 13 deconvloution layers and 5 unpooling layers. Attached to pixelwise classifier. \n",
    "We assumed that we only have two classes.\n",
    "Still missing the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input, scope=\"SegNet\", reuse=True):\n",
    "    input = tf.reshape(input, [-1, 256, 256, 1])\n",
    "    n_labels = 2\n",
    "    with tf.name_scope(scope):\n",
    "        # first layer\n",
    "        conv_1 = conv_layer(input, 64)\n",
    "        conv_2 = conv_layer(conv_1, 64)\n",
    "        pool_1, indicies_1 = maxpool_layer(conv_2)\n",
    "        \n",
    "        # second layer\n",
    "        conv_3 = conv_layer(pool_1, 128)\n",
    "        conv_4 = conv_layer(conv_3, 128)\n",
    "        pool_2, indicies_2 = maxpool_layer(conv_4)\n",
    "        \n",
    "        #third layer\n",
    "        conv_5 = conv_layer(pool_2, 256)\n",
    "        conv_6 = conv_layer(conv_5, 256)\n",
    "        conv_7 = conv_layer(conv_6, 256)\n",
    "        pool_3, indicies_3 = maxpool_layer(conv_7)\n",
    "        \n",
    "        #fourth layer\n",
    "        conv_8 = conv_layer(pool_3, 512)\n",
    "        conv_9 = conv_layer(conv_8, 512)\n",
    "        conv_10 = conv_layer(conv_9, 512)\n",
    "        pool_4, indicies_4 = maxpool_layer(conv_10)\n",
    "        \n",
    "        #fifth layer\n",
    "        conv_11 = conv_layer(pool_4, 512)\n",
    "        conv_12 = conv_layer(conv_11, 512)\n",
    "        conv_13 = conv_layer(conv_12, 512)\n",
    "        pool_5, indicies_5 = maxpool_layer(conv_13)\n",
    "        \n",
    "        \n",
    "        # the decoding layers\n",
    "        # fifth layer\n",
    "        unpool_5 = unpool_layer(pool_5, indicies_5)\n",
    "        deconv_13 = deconv_layer(unpool_5, 512)\n",
    "        deconv_12 = deconv_layer(deconv_13, 512)\n",
    "        deconv_11 = deconv_layer(deconv_12, 512)\n",
    "       \n",
    "        \n",
    "        # forth layer\n",
    "        unpool_4 = unpool_layer(deconv_11, indicies_4)\n",
    "        deconv_10 = deconv_layer(unpool_4, 512)\n",
    "        deconv_9 = deconv_layer(deconv_10, 512)\n",
    "        deconv_8 = deconv_layer(deconv_9, 256)\n",
    "        \n",
    "        \n",
    "        # third layer\n",
    "        unpool_3 = unpool_layer(deconv_8, indicies_3)\n",
    "        deconv_7 = deconv_layer(unpool_3, 256)\n",
    "        deconv_6 = deconv_layer(deconv_7, 256)\n",
    "        deconv_5 = deconv_layer(deconv_6, 128)\n",
    "        \n",
    "        # second layer\n",
    "        unpool_2 = unpool_layer(deconv_5, indicies_2)\n",
    "        deconv_4 = deconv_layer(unpool_2, 128)\n",
    "        deconv_3 = deconv_layer(deconv_4, 64)\n",
    "        \n",
    "        # first layer\n",
    "        unpool_1 = unpool_layer(deconv_3, indicies_1)\n",
    "        deconv_2 = deconv_layer(unpool_1, 64)\n",
    "        #deconv_1 = deconv_layer(deconv_2, 64)\n",
    "        \n",
    "        # Classification\n",
    "        classifier_layer = conv_layer(deconv_2, n_labels, kernel_size = 1)\n",
    "        softmax = tf.nn.softmax(classifier_layer)\n",
    "        print(softmax.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the model is working properly with the liver input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"SegNet_13/conv2d_15/convolution:0\", shape=(1, 16, 16, 512), dtype=float32)\n",
      "Tensor(\"SegNet_13/MaxPoolWithArgmax_3:1\", shape=(1, 16, 16, 512), dtype=int64)\n",
      "Tensor(\"SegNet_13/conv2d_18/convolution:0\", shape=(1, 32, 32, 256), dtype=float32)\n",
      "Tensor(\"SegNet_13/MaxPoolWithArgmax_2:1\", shape=(1, 32, 32, 256), dtype=int64)\n",
      "(1, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "im = cv2.imread('liver.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "im = cv2.resize(im,(256,256))\n",
    "im = np.array(im, dtype=np.float32)\n",
    "im = np.expand_dims(im, axis = 0)\n",
    "im = np.expand_dims(im, axis = 3)\n",
    "model(im)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
